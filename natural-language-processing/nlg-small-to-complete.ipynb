{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561c3744",
   "metadata": {},
   "source": [
    "## Language modeling and generation -- a very basic example\n",
    "\n",
    "This notebook provides a dirty and quick way to train a language model (LM) and generate text from it. It does not correspond to what's done in practice which requires a lot more manipulation to get the model state and pass it on from one cell to another: see, e.g., https://www.tensorflow.org/text/tutorials/text_generation?hl=en. For a first approach to language modeling and generation, I'd rather avoid this loop and go for a simpler option.\n",
    "\n",
    "In this very basic version, we will thus train a LSTM as an n-gram model to encode a fixed number of tokens (say n, so we consider a n+1-gram model) and predict the next token from a fixed length history. Preparing training data is easy as all inputs are fixed length. So is prediction as long as we have a seed of n tokens to start with. We do so to illustrate n-grams, the notion of summarizing a sequence with a RNN state (the last one in this case), LSTM training and the most simple loop of text generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57d5904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 20:14:42.276547: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-05 20:14:42.276618: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-05 20:14:42.276657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-05 20:14:42.286623: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load a bunch of modules\n",
    "#\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 20:14:44.944325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:14:44.956327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:14:44.956500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c308741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized text[i] = ['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem', '.', 'imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny', '!', 'maureen', 'stapleton', 'is', 'a', 'scene', 'stealer', '.', 'the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream', '.', 'watch', 'for', 'alan', 'the', 'skipper', 'hale', 'jr.', 'as', 'a', 'police', 'sgt', '.']\n",
      "tokenized text[i] = ['bizarre', 'horror', 'movie', 'filled', 'with', 'famous', 'faces', 'but', 'stolen', 'by', 'cristina', 'raines', 'later', 'of', 'tv', \"'s\", 'flamingo', 'road', 'as', 'a', 'pretty', 'but', 'somewhat', 'unstable', 'model', 'with', 'a', 'gummy', 'smile', 'who', 'is', 'slated', 'to', 'pay', 'for', 'her', 'attempted', 'suicides', 'by', 'guarding', 'the', 'gateway', 'to', 'hell', '!', 'the', 'scenes', 'with', 'raines', 'modeling', 'are', 'very', 'well', 'captured', ',', 'the', 'mood', 'music', 'is', 'perfect', ',', 'deborah', 'raffin', 'is', 'charming', 'as', 'cristina', \"'s\", 'pal', ',', 'but', 'when', 'raines', 'moves', 'into', 'a', 'creepy', 'brooklyn', 'heights', 'brownstone', 'inhabited', 'by', 'a', 'blind', 'priest', 'on', 'the', 'top', 'floor', ',', 'things', 'really', 'start', 'cooking', '.', 'the', 'neighbors', ',', 'including', 'a', 'fantastically', 'wicked', 'burgess', 'meredith', 'and', 'kinky', 'couple', 'sylvia', 'miles', '&', 'beverly', \"d'angelo\", ',', 'are', 'a', 'diabolical', 'lot', ',', 'and', 'eli', 'wallach', 'is', 'great', 'fun', 'as', 'a', 'wily', 'police', 'detective', '.', 'the', 'movie', 'is', 'nearly', 'a', 'cross-pollination', 'of', 'rosemary', \"'s\", 'baby', 'and', 'the', 'exorcist', 'but', 'what', 'a', 'combination', '!', 'based', 'on', 'the', 'best-seller', 'by', 'jeffrey', 'konvitz', ',', 'the', 'sentinel', 'is', 'entertainingly', 'spooky', ',', 'full', 'of', 'shocks', 'brought', 'off', 'well', 'by', 'director', 'michael', 'winner', ',', 'who', 'mounts', 'a', 'thoughtfully', 'downbeat', 'ending', 'with', 'skill', '.', '1/2', 'from']\n",
      "tokenized text[i] = ['a', 'solid', ',', 'if', 'unremarkable', 'film', '.', 'matthau', ',', 'as', 'einstein', ',', 'was', 'wonderful', '.', 'my', 'favorite', 'part', ',', 'and', 'the', 'only', 'thing', 'that', 'would', 'make', 'me', 'go', 'out', 'of', 'my', 'way', 'to', 'see', 'this', 'again', ',', 'was', 'the', 'wonderful', 'scene', 'with', 'the', 'physicists', 'playing', 'badmitton', ',', 'i', 'loved', 'the', 'sweaters', 'and', 'the', 'conversation', 'while', 'they', 'waited', 'for', 'robbins', 'to', 'retrieve', 'the', 'birdie', '.']\n",
      "tokenized text[i] = ['it', \"'s\", 'a', 'strange', 'feeling', 'to', 'sit', 'alone', 'in', 'a', 'theater', 'occupied', 'by', 'parents', 'and', 'their', 'rollicking', 'kids', '.', 'i', 'felt', 'like', 'instead', 'of', 'a', 'movie', 'ticket', ',', 'i', 'should', 'have', 'been', 'given', 'a', 'nambla', 'membership.', 'based', 'upon', 'thomas', 'rockwell', \"'s\", 'respected', 'book', ',', 'how', 'to', 'eat', 'fried', 'worms', 'starts', 'like', 'any', 'children', \"'s\", 'story', ':', 'moving', 'to', 'a', 'new', 'town', '.', 'the', 'new', 'kid', ',', 'fifth', 'grader', 'billy', 'forrester', 'was', 'once', 'popular', ',', 'but', 'has', 'to', 'start', 'anew', '.', 'making', 'friends', 'is', 'never', 'easy', ',', 'especially', 'when', 'the', 'only', 'prospect', 'is', 'poindexter', 'adam', '.', 'or', 'erica', ',', 'who', 'at', '4', '1/2', 'feet', ',', 'is', 'a', 'giant.', 'further', 'complicating', 'things', 'is', 'joe', 'the', 'bully', '.', 'his', 'freckled', 'face', 'and', 'sleeveless', 'shirts', 'are', 'daunting', '.', 'he', 'antagonizes', 'kids', 'with', 'the', 'death', 'ring', ':', 'a', 'crackerjack', 'ring', 'that', 'is', 'rumored', 'to', 'kill', 'you', 'if', 'you', \"'re\", 'punched', 'with', 'it', '.', 'but', 'not', 'immediately', '.', 'no', ',', 'the', 'death', 'ring', 'unleashes', 'a', 'poison', 'that', 'kills', 'you', 'in', 'the', 'eight', 'grade.', 'joe', 'and', 'his', 'axis', 'of', 'evil', 'welcome', 'billy', 'by', 'smuggling', 'a', 'handful', 'of', 'slimy', 'worms', 'into', 'his', 'thermos', '.', 'once', 'discovered', ',', 'billy', 'plays', 'it', 'cool', ',', 'swearing', 'that', 'he', 'eats', 'worms', 'all', 'the', 'time', '.', 'then', 'he', 'throws', 'them', 'at', 'joe', \"'s\", 'face', '.', 'ewww', '!', 'to', 'win', 'them', 'over', ',', 'billy', 'reluctantly', 'bets', 'that', 'he', 'can', 'eat', '10', 'worms', '.', 'fried', ',', 'boiled', ',', 'marinated', 'in', 'hot', 'sauce', ',', 'squashed', 'and', 'spread', 'on', 'a', 'peanut', 'butter', 'sandwich', '.', 'each', 'meal', 'is', 'dubbed', 'an', 'exotic', 'name', 'like', 'the', 'radioactive', 'slime', 'delight', ',', 'in', 'which', 'the', 'kids', 'finally', 'live', 'out', 'their', 'dream', 'of', 'microwaving', 'a', 'living', 'organism.', 'if', 'you', \"'ve\", 'ever', 'met', 'me', ',', 'you', \"'ll\", 'know', 'that', 'i', 'have', 'an', 'uncontrollably', 'hearty', 'laugh', '.', 'i', 'felt', 'like', 'a', 'creep', 'erupting', 'at', 'a', 'toddler', 'whining', 'that', 'his', 'dilly', 'dick', 'hurts', '.', 'but', 'fried', 'worms', 'is', 'wonderfully', 'disgusting', '.', 'like', 'a', 'g-rated', 'farrelly', 'brothers', 'film', ',', 'it', 'is', 'both', 'vomitous', 'and', 'delightful.', 'writer/director', 'bob', 'dolman', 'is', 'also', 'a', 'savvy', 'storyteller', '.', 'to', 'raise', 'the', 'stakes', 'the', 'worms', 'must', 'be', 'consumed', 'by', '7', 'pm', '.', 'in', 'addition', 'billy', 'holds', 'a', 'dark', 'secret', ':', 'he', 'has', 'an', 'ultra-sensitive', 'stomach.', 'dolman', 'also', 'has', 'a', 'keen', 'sense', 'of', 'perspective', '.', 'with', 'such', 'accuracy', ',', 'he', 'draws', 'on', 'children', \"'s\", 'insecurities', 'and', 'tendency', 'to', 'exaggerate', 'mundane', 'dilemmas.', 'if', 'you', 'were', 'to', 'hyperbolize', 'this', 'movie', 'the', 'way', 'kids', 'do', 'their', 'quandaries', ',', 'you', 'will', 'see', 'that', 'it', 'is', 'essentially', 'about', 'war', '.', 'freedom-fighter', 'and', 'freedom-hater', 'use', 'pubescent', 'boys', 'as', 'pawns', 'in', 'proxy', 'wars', ',', 'only', 'to', 'learn', 'a', 'valuable', 'lesson', 'in', 'unity', '.', 'international', 'leaders', 'can', 'learn', 'a', 'thing', 'or', 'two', 'about', 'global', 'peacekeeping', 'from', 'fried', 'worms.', 'at', 'the', 'end', 'of', 'the', 'film', ',', 'i', 'was', 'comforted', 'when', 'two', 'chaperoning', 'mothers', 'behind', 'me', ',', 'looked', 'at', 'each', 'other', 'with', 'befuddlement', 'and', 'agreed', ',', 'that', 'was', 'a', 'great', 'movie', '.', 'great', ',', 'now', 'i', 'wo', \"n't\", 'have', 'to', 'register', 'myself', 'in', 'any', 'lawful', 'databases', '.']\n",
      "tokenized text[i] = ['you', 'probably', 'all', 'already', 'know', 'this', 'by', 'now', ',', 'but', '5', 'additional', 'episodes', 'never', 'aired', 'can', 'be', 'viewed', 'on', 'abc.com', 'i', \"'ve\", 'watched', 'a', 'lot', 'of', 'television', 'over', 'the', 'years', 'and', 'this', 'is', 'possibly', 'my', 'favorite', 'show', ',', 'ever', '.', 'it', \"'s\", 'a', 'crime', 'that', 'this', 'beautifully', 'written', 'and', 'acted', 'show', 'was', 'canceled', '.', 'the', 'actors', 'that', 'played', 'laura', ',', 'whit', ',', 'carlos', ',', 'mae', ',', 'damian', ',', 'anya', 'and', 'omg', ',', 'steven', 'caseman', 'are', 'all', 'incredible', 'and', 'so', 'natural', 'in', 'those', 'roles', '.', 'even', 'the', 'kids', 'are', 'great', '.', 'wonderful', 'show', '.', 'so', 'sad', 'that', 'it', \"'s\", 'gone', '.', 'of', 'course', 'i', 'wonder', 'about', 'the', 'reasons', 'it', 'was', 'canceled', '.', 'there', 'is', 'no', 'way', 'i', \"'ll\", 'let', 'myself', 'believe', 'that', 'ms.', 'moynahan', \"'s\", 'pregnancy', 'had', 'anything', 'to', 'do', 'with', 'it', '.', 'it', 'was', 'in', 'the', 'perfect', 'time', 'slot', 'in', 'this', 'market', '.', 'i', \"'ve\", 'watched', 'all', 'the', 'episodes', 'again', 'on', 'abc.com', 'i', 'hope', 'they', 'all', 'come', 'out', 'on', 'dvd', 'some', 'day', '.', 'thanks', 'for', 'reading', '.']\n",
      "tokenized text[i] = ['i', 'saw', 'the', 'movie', 'with', 'two', 'grown', 'children', '.', 'although', 'it', 'was', 'not', 'as', 'clever', 'as', 'shrek', ',', 'i', 'thought', 'it', 'was', 'rather', 'good', '.', 'in', 'a', 'movie', 'theatre', 'surrounded', 'by', 'children', 'who', 'were', 'on', 'spring', 'break', ',', 'there', 'was', 'not', 'a', 'sound', 'so', 'i', 'know', 'the', 'children', 'all', 'liked', 'it', '.', 'there', 'parents', 'also', 'seemed', 'engaged', '.', 'the', 'death', 'and', 'apparent', 'death', 'of', 'characters', 'brought', 'about', 'the', 'appropriate', 'gasps', 'and', 'comments', '.', 'hopefully', 'people', 'realize', 'this', 'movie', 'was', 'made', 'for', 'kids', '.', 'as', 'such', ',', 'it', 'was', 'successful', 'although', 'i', 'liked', 'it', 'too', '.', 'personally', 'i', 'liked', 'the', 'scrat', '!', '!']\n",
      "tokenized text[i] = ['you', \"'re\", 'using', 'the', 'imdb.', 'you', \"'ve\", 'given', 'some', 'hefty', 'votes', 'to', 'some', 'of', 'your', 'favourite', 'films.', 'it', \"'s\", 'something', 'you', 'enjoy', 'doing.', 'and', 'it', \"'s\", 'all', 'because', 'of', 'this', '.', 'fifty', 'seconds', '.', 'one', 'world', 'ends', ',', 'another', 'begins.', 'how', 'can', 'it', 'not', 'be', 'given', 'a', 'ten', '?', 'i', 'wonder', 'at', 'those', 'who', 'give', 'this', 'a', 'seven', 'or', 'an', 'eight', '...', 'exactly', 'how', 'could', 'the', 'first', 'film', 'ever', 'made', 'be', 'better', '?', 'for', 'the', 'record', ',', 'the', 'long', ',', 'still', 'opening', 'shot', 'is', 'great', 'showmanship', ',', 'a', 'superb', 'innovation', ',', 'perfectly', 'suited', 'to', 'the', 'situation', '.', 'and', 'the', 'dog', 'on', 'the', 'bike', 'is', 'a', 'lovely', 'touch', '.', 'all', 'this', 'within', 'fifty', 'seconds.', 'the', 'word', 'genius', 'is', 'often', 'overused.', 'this', 'is', 'genius', '.']\n",
      "tokenized text[i] = ['this', 'was', 'a', 'good', 'film', 'with', 'a', 'powerful', 'message', 'of', 'love', 'and', 'redemption', '.', 'i', 'loved', 'the', 'transformation', 'of', 'the', 'brother', 'and', 'the', 'repercussions', 'of', 'the', 'horrible', 'disease', 'on', 'the', 'family', '.', 'well-acted', 'and', 'well-directed', '.', 'if', 'there', 'were', 'any', 'flaws', ',', 'i', \"'d\", 'have', 'to', 'say', 'that', 'the', 'story', 'showed', 'the', 'typical', 'suburban', 'family', 'and', 'their', 'difficulties', 'again', '.', 'what', 'about', 'all', 'people', 'of', 'all', 'cultural', 'backgrounds', '?', 'i', 'would', 'love', 'to', 'see', 'a', 'movie', 'where', 'all', 'of', 'these', 'cultures', 'are', 'shown', 'like', 'in', 'real', 'life', '.', 'nevertheless', ',', 'the', 'film', 'soared', 'in', 'terms', 'of', 'its', 'values', 'and', 'its', 'understanding', 'of', 'the', 'how', 'a', 'disease', 'can', 'bring', 'someone', 'closer', 'to', 'his', 'or', 'her', 'maker', '.', 'loved', 'the', 'film', 'and', 'it', 'brought', 'tears', 'to', 'my', 'eyes']\n",
      "tokenized text[i] = ['made', 'after', 'quartet', 'was', ',', 'trio', 'continued', 'the', 'quality', 'of', 'the', 'earlier', 'film', 'versions', 'of', 'the', 'short', 'stories', 'by', 'maugham', '.', 'here', 'the', 'three', 'stories', 'are', 'the', 'verger', ',', 'mr.', 'know-it-all', ',', 'and', 'sanitorium', '.', 'the', 'first', 'two', 'are', 'comic', 'the', 'verger', 'is', 'like', 'a', 'prolonged', 'joke', ',', 'but', 'one', 'with', 'a', 'good', 'pay-off', ',', 'and', 'the', 'last', 'more', 'serious', 'as', 'health', 'issues', 'are', 'involved', '.', 'again', 'the', 'author', 'introduces', 'the', 'film', 'and', 'the', 'stories.', 'james', 'hayter', ',', 'soon', 'to', 'have', 'his', 'signature', 'role', 'as', 'samuel', 'pickwick', ',', 'is', 'the', 'hero', 'in', 'the', 'verger', '.', 'he', 'holds', 'this', 'small', 'custodial-type', 'job', 'in', 'a', 'church', ',', 'but', 'the', 'new', 'vicar', 'michael', 'hordern', 'is', 'an', 'intellectual', 'snob', '.', 'when', 'he', 'hears', 'hayter', 'has', 'no', 'schooling', 'he', 'fires', 'him', '.', 'hayter', 'has', 'saved', 'some', 'money', ',', 'so', 'he', 'tells', 'his', 'wife', 'kathleen', 'harrison', 'he', 'fancies', 'buying', 'a', 'small', 'news', 'and', 'tobacco', 'shop', '.', 'he', 'has', 'a', 'good', 'eye', ',', 'and', 'his', 'store', 'thrives', '.', 'soon', 'he', 'has', 'a', 'whole', 'chain', 'of', 'stores', '.', 'when', 'his', 'grandchild', 'is', 'christened', 'by', 'hordern', ',', 'the', 'latter', 'is', 'amazed', 'to', 'see', 'how', 'prosperous', 'his', 'ex-verger', '.', 'the', 'payoff', 'is', 'when', 'bank', 'manager', 'felix', 'aylmer', 'meets', 'with', 'hayter', 'about', 'diversifying', 'his', 'investments', '.', 'i', \"'ll\", 'leave', 'it', 'to', 'you', 'to', 'hear', 'the', 'unintentional', 'but', 'ironic', 'coda', 'of', 'the', 'meeting.', 'according', 'to', 'maugham', 'he', 'met', 'a', 'man', 'like', 'max', 'kelada', 'nigel', 'patrick', 'on', 'a', 'cruise', '.', 'in', 'mr.', 'know-it-all', 'kelada', 'is', 'a', 'splashy', ',', 'friendly', ',', 'and', 'slightly', 'overbearing', 'type', 'from', 'the', 'middle', 'east', 'who', 'is', 'on', 'a', 'business', 'trip', 'regarding', 'jewelry', 'by', 'steamship', '.', 'his', 'state-room', 'mate', 'is', 'mr.', 'grey', 'the', 'ever', 'quiet', 'and', 'proper', 'wilfred', 'hyde-white', 'who', 'is', 'somewhat', ',', 'silently', 'disapproving', 'of', 'max', '.', 'max', 'likes', 'to', 'enliven', 'things', ',', 'and', 'soon', 'is', 'heavily', 'involved', 'in', 'the', 'ship', \"'s\", 'entertainment', '.', 'at', 'this', 'point', 'the', 'story', 'actually', 'resembles', 'part', 'of', 'the', 'plot', 'of', 'the', 'non-maugham', 'story', 'and', 'film', 'china', 'seas', '1935', ',', 'as', 'max', 'makes', 'a', 'bet', 'that', 'he', 'can', 'tell', 'a', 'real', 'piece', 'of', 'jewelry', 'from', 'a', 'fake', 'after', 'insisting', 'that', 'a', 'piece', 'of', 'jewelry', 'he', 'spotted', 'is', 'real', '.', 'i', 'wo', \"n't\", 'describe', 'the', 'way', 'max', 'rises', 'to', 'the', 'occasion.', 'sanitorium', 'is', 'the', 'longest', 'segment', '.', 'roland', 'culver', 'plays', 'ashenden', 'the', 'fictional', 'alter-ego', 'of', 'maugham', 'a', 'writer', 'and', 'one', 'time', 'spy', 'as', 'in', 'hitchcock', \"'s\", 'the', 'secret', 'agent', '.', 'here', 'he', 'has', 'to', 'use', 'a', 'sanitorium', 'for', 'a', 'couple', 'of', 'months', 'for', 'his', 'health', '.', 'he', 'finds', 'a', 'remarkable', 'crew', 'of', 'people', ',', 'including', 'jean', 'simmons', 'as', 'a', 'frail', 'but', 'beautiful', 'young', 'woman', ',', 'finlay', 'currie', 'as', 'an', 'irascible', 'scotsman', ',', 'john', 'laurie', 'as', 'a', 'second', 'irascible', 'scotsman', 'who', 'is', 'at', 'war', 'with', 'currie', ',', 'raymond', 'huntley', 'as', 'a', 'quiet', 'patient', 'who', 'only', 'shows', 'his', 'internal', 'anger', 'at', 'his', 'situation', 'when', 'his', 'wife', 'shows', 'up', ',', 'and', 'michael', 'rennie', 'as', 'a', 'young', 'man', 'who', 'has', 'a', 'serious', 'life', 'threatening', 'illness', '.', 'culver', 'watches', 'as', 'three', 'stories', 'among', 'these', 'characters', 'play', 'out', 'to', 'their', 'conclusions', '.', 'the', 'last', ',', 'dealing', 'with', 'simmons', 'and', 'rennie', ',', 'is', 'ironic', 'but', 'deeply', 'moving.', 'it', 'was', 'a', 'dandy', 'follow-up', 'to', 'the', 'earlier', 'quartet', ',', 'and', 'well', 'worth', 'watching', '.']\n",
      "tokenized text[i] = ['for', 'a', 'mature', 'man', ',', 'to', 'admit', 'that', 'he', 'shed', 'a', 'tear', 'over', 'this', 'film', 'is', 'a', 'mature', 'response', ',', 'to', 'a', 'mature', 'film.', 'if', 'one', 'need', 'admit', 'more', 'then', 'perhaps', 'one', 'could', 'say', 'that', ',', 'life', 'can', 'never', 'be', 'the', 'same', ',', 'after', 'viewing', 'such', 'advent', 'for', 'it', 'has', 'moved', 'us', 'to', 'the', 'next', 'level.']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load IMDb data and process a small number of samples (positive here)\n",
    "#\n",
    "fn = 'imdb-trn.json'\n",
    "\n",
    "with open(fn, 'rt') as f:\n",
    "    imdb_data = json.load(f)\n",
    "    \n",
    "\n",
    "imdb_data_small = imdb_data[:2000] + imdb_data[-2000:]\n",
    "\n",
    "\n",
    "def clean_utterance(buf):\n",
    "    '''\n",
    "    Clean the list of tokens.\n",
    "    '''\n",
    "    ignore = (\"``\", \"''\", \"(\", \")\", '<', 'br', '/', '>', '--', '*', '-')\n",
    "    \n",
    "    return [x.lower() for x in buf if x.lower() not in ignore]\n",
    "\n",
    "\n",
    "#\n",
    "# tokenize IMDb texts with NLTK tokenizer after lowercasing\n",
    "#\n",
    "pos_texts = [clean_utterance(word_tokenize(x[1])) for x in imdb_data if x[0] == 'pos']\n",
    "\n",
    "for i in range(10):\n",
    "    print('tokenized text[i] =', pos_texts[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3529c3",
   "metadata": {},
   "source": [
    "### Prepare the vocabulary on which we will operate\n",
    "\n",
    "This is the standard stuff that you'll rapidly get used to. Here we make a list of tokens in the dataset with the number of occurrences for each then (severely) limit the vocabulary to tokens appearing more than MINOCC times (defaults to 30). We add an <unk> token to replace tokens not in the selected vocabulary. We finally construct a word2id mapping (dictionary) and the inverse id2word mapping (list).\n",
    "    \n",
    "We provide in the next cell two useful functions to encode/decode a sequence: list of strings to list of integers for the former, and conversely for the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538bf5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of tokens in dataset = 77041\n",
      "most frequent tokens:\n",
      "   the                   172318\n",
      "   ,                     144077\n",
      "   .                     117678\n",
      "   and                   89398\n",
      "   a                     83300\n",
      "   of                    76630\n",
      "   to                    66455\n",
      "   is                    58467\n",
      "   in                    49797\n",
      "   it                    47350\n",
      "   i                     40267\n",
      "   that                  35526\n",
      "   this                  34881\n",
      "   's                    32132\n",
      "   as                    26253\n",
      "   with                  23197\n",
      "   was                   22685\n",
      "   for                   22303\n",
      "   but                   20731\n",
      "   film                  20284\n",
      "\n",
      "least frequent tokens:\n",
      "   vulgarities           1\n",
      "   rêves                 1\n",
      "   objectifier           1\n",
      "   disaster.one          1\n",
      "   ketty                 1\n",
      "   konstadinou           1\n",
      "   kavogianni            1\n",
      "   'guilty               1\n",
      "   laughing.every        1\n",
      "   heart.my              1\n",
      "   vassilis              1\n",
      "   haralambopoulos       1\n",
      "   athinodoros           1\n",
      "   prousalis             1\n",
      "   nikolaidis            1\n",
      "   tv.in                 1\n",
      "   ant1                  1\n",
      "   zones.we              1\n",
      "   imy                   1\n",
      "   jayden                1\n",
      "\n",
      "total number of tokens in vocab = 6505\n",
      "[('<unk>', 0), ('the', 1), (',', 2), ('.', 3), ('and', 4), ('a', 5), ('of', 6), ('to', 7), ('is', 8), ('in', 9), ('it', 10), ('i', 11), ('that', 12), ('this', 13), (\"'s\", 14), ('as', 15), ('with', 16), ('was', 17), ('for', 18), ('but', 19)]\n",
      "['<unk>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i', 'that', 'this', \"'s\", 'as', 'with', 'was', 'for', 'but']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_token_counts(idata, use_lemma = False):\n",
    "    '''\n",
    "    Create vocabulary from a bunch of (tokenized) texts. If use_lemma == True, use lemma rather than\n",
    "    tokens. \n",
    "    \n",
    "    Returns:\n",
    "        - token count (dict)\n",
    "    '''\n",
    "\n",
    "    tokcnt = {}    \n",
    "    \n",
    "    for utterance in idata:\n",
    "        for i, token in enumerate(utterance):\n",
    "            tokcnt[token] = 1 if token not in tokcnt else tokcnt[token] + 1\n",
    "\n",
    "    return dict(sorted(tokcnt.items(), key=lambda x: x[1], reverse = True))\n",
    "\n",
    "\n",
    "count = get_token_counts(pos_texts)\n",
    "\n",
    "#\n",
    "# Pretty print a number of things\n",
    "#\n",
    "print('total number of tokens in dataset =', len(count))\n",
    "print('most frequent tokens:')\n",
    "for x in list(count.keys())[:20]:\n",
    "    print(f\"   {x:20}  {count[x]}\")\n",
    "print('\\nleast frequent tokens:')\n",
    "for x in list(count.keys())[-20:]:\n",
    "    print(f\"   {x:20}  {count[x]}\")\n",
    "\n",
    "#\n",
    "# Select vocabulary: here, we will limit ourselves to tokens occurring at least MINOCC times and map the remaining\n",
    "# ones to <unk>. So IDs of actual tokens will start at 1 and we reserve 0 for <unk>.\n",
    "#\n",
    "\n",
    "MINOCC = 30\n",
    "\n",
    "word2id = {x: i+1 for i, x in enumerate([x for x in count if count[x] > MINOCC])}\n",
    "word2id = {'<unk>': 0, **word2id} # this is a quick way to merge dictionaries in pyton 3.9 -- see https://stackoverflow.com/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression-in-python\n",
    "\n",
    "vocsize = len(word2id)\n",
    "\n",
    "print('\\ntotal number of tokens in vocab =', vocsize)\n",
    "print(list(word2id.items())[:20])\n",
    "\n",
    "# also reverse mapping for pretty printing\n",
    "id2word = list(word2id.keys())\n",
    "print(id2word[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd059ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem', '.', 'imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny', '!', 'maureen', 'stapleton', 'is', 'a', 'scene', 'stealer', '.', 'the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream', '.', 'watch', 'for', 'alan', 'the', 'skipper', 'hale', 'jr.', 'as', 'a', 'police', 'sgt', '.']\n",
      "[18, 5, 21, 12, 231, 90, 1144, 46, 268, 26, 5, 166, 6, 648, 4172, 4427, 18, 13, 1031, 3, 918, 5, 21, 125, 772, 0, 8, 190, 182, 33, 5351, 0, 8, 5, 136, 0, 3, 1, 0, 114, 8, 36, 1744, 2434, 3, 117, 18, 1283, 1, 0, 0, 1837, 15, 5, 531, 6210, 3]\n",
      "['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem', '.', 'imagine', 'a', 'movie', 'where', 'joe', '<unk>', 'is', 'actually', 'funny', '!', 'maureen', '<unk>', 'is', 'a', 'scene', '<unk>', '.', 'the', '<unk>', 'character', 'is', 'an', 'absolute', 'scream', '.', 'watch', 'for', 'alan', 'the', '<unk>', '<unk>', 'jr.', 'as', 'a', 'police', 'sgt', '.']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Define utility function. To simplify the code, we will use global variables (which is not recommended)\n",
    "# \n",
    "\n",
    "def encode_sequence(data):\n",
    "    '''\n",
    "    Return the encoded sequence given the tokens' strings and the word2id mapping. We assume <unk> is at index 0\n",
    "    '''\n",
    "    global word2id\n",
    "    \n",
    "    return [word2id.get(x, 0) for x in data]\n",
    "\n",
    "def decode_sequence(data):\n",
    "    '''\n",
    "    Return the decoded sequence given the tokens' encodings and id2word mapping\n",
    "    '''\n",
    "    global id2word\n",
    "    \n",
    "    return [id2word[x] for x in data]\n",
    "            \n",
    "  \n",
    "enc = encode_sequence(pos_texts[0])\n",
    "print(pos_texts[0])\n",
    "print(enc)\n",
    "print(decode_sequence(enc)) \n",
    "# print(sequence_has_unk(enc))\n",
    "# print(sequence_has_unk(enc[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7589d4c",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "We firsty prepare training data for this simplified problem. Training data consists of fixed-length sequences with the corresponding label, i.e., the token that follows (all of these encoded as integers of course):\n",
    "   ['for', 'a', 'movie', 'that', 'gets']  >>  no\n",
    "   ['that', 'gets', 'no', 'respect', 'there']  >>  sure\n",
    "   ['respect', 'there', 'sure', 'are', 'a']  >>  lot\n",
    "   ['are', 'a', 'lot', 'of', 'memorable']  >>  quotes\n",
    "   \n",
    "As we will design a closed vocabulary LM (i.e., no possibility of assigning probability to the <unk> token), we discard sequences (history and label) where <unk> appears. As training data are documents rather than sentences, we also avoid sequences with end of sentence punctuation marks in the history (here, only the period is considered).\n",
    "    \n",
    "We then define the model's architecture, wich is simply a LSTM to encore the history followed by a dense projection. And infally train the model, which might take some time if you have no GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6821e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences for training = 549932\n",
      "number of sequences fdiscarded = 527827\n",
      "   ['for', 'a', 'movie', 'that', 'gets']  >>  no\n",
      "   ['that', 'gets', 'no', 'respect', 'there']  >>  sure\n",
      "   ['respect', 'there', 'sure', 'are', 'a']  >>  lot\n",
      "   ['are', 'a', 'lot', 'of', 'memorable']  >>  quotes\n",
      "   ['of', 'memorable', 'quotes', 'listed', 'for']  >>  this\n",
      "   ['character', 'is', 'an', 'absolute', 'scream']  >>  .\n",
      "   ['jr.', 'as', 'a', 'police', 'sgt']  >>  .\n",
      "   ['bizarre', 'horror', 'movie', 'filled', 'with']  >>  famous\n",
      "   ['filled', 'with', 'famous', 'faces', 'but']  >>  stolen\n",
      "   ['to', 'hell', '!', 'the', 'scenes']  >>  with\n",
      "   ['very', 'well', 'captured', ',', 'the']  >>  mood\n",
      "   [',', 'the', 'mood', 'music', 'is']  >>  perfect\n",
      "   [',', 'but', 'when', 'raines', 'moves']  >>  into\n",
      "   ['raines', 'moves', 'into', 'a', 'creepy']  >>  brooklyn\n",
      "   ['by', 'a', 'blind', 'priest', 'on']  >>  the\n",
      "   ['priest', 'on', 'the', 'top', 'floor']  >>  ,\n",
      "   ['top', 'floor', ',', 'things', 'really']  >>  start\n",
      "   ['what', 'a', 'combination', '!', 'based']  >>  on\n",
      "   ['full', 'of', 'shocks', 'brought', 'off']  >>  well\n",
      "   ['brought', 'off', 'well', 'by', 'director']  >>  michael\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# That's where we will simplify things very seriously to train a LSTM that can predict the following token. We will\n",
    "# artificially build fixed length input sequences from the training data with the following word as the label to \n",
    "# predict. This is a rather dirty hack but highly facilitates life.\n",
    "#\n",
    "\n",
    "input_length = 5     # increase to account for longer histories\n",
    "step = 3             # reduce to yield more training samples\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "nignored = 0\n",
    "\n",
    "for i, utterance in enumerate(pos_texts):\n",
    "    # print('utterance', i, '=', utterance)\n",
    "    \n",
    "    for j in range(0, len(utterance) - input_length, step):\n",
    "        buf = encode_sequence(utterance[j:j+input_length])\n",
    "        label = word2id.get(utterance[j+input_length], 0) # assuming <unk> at index 0\n",
    "        \n",
    "        # let's make our life easier and stick to sequences and labels that are not <unk>,\n",
    "        # also disregarding sequences with punctuation marks in the history (so we can stop)\n",
    "        # generation whenever a question mark is selected. We limit ourselves to '.' but\n",
    "        # should consider '!' and '?' also if things were to be done properly.\n",
    "        \n",
    "        if 0 not in buf and word2id['.'] not in buf and label != 0:\n",
    "            X.append(buf)\n",
    "            Y.append(label)\n",
    "            # print('     j =', j, decode_sequence(buf), ' >>>', id2word[label], '     [ok]')\n",
    "        else:\n",
    "            nignored += 1\n",
    "            # print('     j =', j, decode_sequence(buf), ' >>>', id2word[label], '     [ignored]')\n",
    "\n",
    "print('number of sequences for training =', len(X))\n",
    "print('number of sequences fdiscarded =', nignored)\n",
    "\n",
    "#\n",
    "# Finally, convert data to numpy for later use with tf.keras (not sure it is necessary)\n",
    "#\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "for i in range(20):\n",
    "    print('  ', decode_sequence(X[i]), ' >> ', id2word[Y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce63820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 20:15:00.999051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:15:00.999290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:15:00.999437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:15:01.070290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:15:01.070487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:15:01.070618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-05 20:15:01.070725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4279 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5, 100)            650500    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6505)              657005    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1387905 (5.29 MB)\n",
      "Trainable params: 1387905 (5.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Define the model and the hyperparameters such as embedding dimension and LSTM state dimension.\n",
    "#\n",
    "\n",
    "\n",
    "embedding_size = 100\n",
    "lstm_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocsize, embedding_size, input_length = input_length))\n",
    "model.add(LSTM(lstm_size))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(vocsize, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam')\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f60a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 20:15:25.383106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-12-05 20:15:25.955475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb008b346c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-05 20:15:25.955494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-12-05 20:15:25.959364: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-05 20:15:26.021020: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - ETA: 0s - loss: 5.8673INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - 25s 7ms/step - loss: 5.8673 - val_loss: 5.4216\n",
      "Epoch 2/40\n",
      "3438/3438 [==============================] - ETA: 0s - loss: 5.2442INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - 14s 4ms/step - loss: 5.2442 - val_loss: 5.1445\n",
      "Epoch 3/40\n",
      "3426/3438 [============================>.] - ETA: 0s - loss: 4.9982INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - 14s 4ms/step - loss: 4.9984 - val_loss: 5.0302\n",
      "Epoch 4/40\n",
      "3438/3438 [==============================] - ETA: 0s - loss: 4.8393INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - 13s 4ms/step - loss: 4.8393 - val_loss: 4.9692\n",
      "Epoch 5/40\n",
      "3435/3438 [============================>.] - ETA: 0s - loss: 4.7165INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - 14s 4ms/step - loss: 4.7163 - val_loss: 4.9382\n",
      "Epoch 6/40\n",
      "3438/3438 [==============================] - ETA: 0s - loss: 4.6117INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - 13s 4ms/step - loss: 4.6117 - val_loss: 4.9221\n",
      "Epoch 7/40\n",
      "3437/3438 [============================>.] - ETA: 0s - loss: 4.5214INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5.x/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438/3438 [==============================] - 13s 4ms/step - loss: 4.5214 - val_loss: 4.9198\n",
      "Epoch 8/40\n",
      "3438/3438 [==============================] - 12s 3ms/step - loss: 4.4404 - val_loss: 4.9283\n",
      "Epoch 9/40\n",
      "3438/3438 [==============================] - 12s 3ms/step - loss: 4.3664 - val_loss: 4.9412\n",
      "Epoch 10/40\n",
      "3438/3438 [==============================] - 12s 3ms/step - loss: 4.2971 - val_loss: 4.9580\n",
      "Epoch 11/40\n",
      "3438/3438 [==============================] - 12s 3ms/step - loss: 4.2307 - val_loss: 4.9785\n",
      "Epoch 12/40\n",
      "3438/3438 [==============================] - 12s 3ms/step - loss: 4.1699 - val_loss: 5.0019\n",
      "Epoch 12: early stopping\n",
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5-final.x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data.NOSAVE/lstm-10-5-final.x/assets\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# And finally run training with an early stopping criterion\n",
    "#\n",
    "\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 128\n",
    "val_split = 0.2\n",
    "\n",
    "stop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 1, mode = 'auto')\n",
    "save = ModelCheckpoint('data.NOSAVE/lstm-10-5.x', monitor = 'val_loss', verbose = 0, save_best_only = True)\n",
    "\n",
    "history = model.fit(X, Y, batch_size = batch_size, epochs = epochs, verbose = 1, validation_split = val_split, callbacks = [stop, save])\n",
    "    \n",
    "model.save('data.NOSAVE/lstm-10-5-final.x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33223f8",
   "metadata": {},
   "source": [
    "### Playing with the model\n",
    "\n",
    "Now we have a properly trained model able to take in a few tokens and output a probability distribution function over the vocabulary for the next position (i.e., p[.|h]). And we can do a few things with this:\n",
    "  - visualize the distribution p[.|h] for a given history\n",
    "  - see in actual utterances how prediction differs from reality (also looking at probabilities)\n",
    "  - compute perplexity on a smal dataset (could be done with + and - samples)\n",
    "  - generate reviews from a prompt\n",
    "  \n",
    "We will not do every of these (you can do that for yourself) but only go through the second and fourth points.\n",
    "\n",
    "We will first prepare unseen data in the same way as above and see how prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f9190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positive sequences for testing = 2142\n",
      "number of negative sequences for testing = 2405\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Get a few unseen texts from the database and process them\n",
    "#\n",
    "[clean_utterance(word_tokenize(x[1])) for x in imdb_data if x[0] == 'pos']\n",
    "\n",
    "pos_tests = [clean_utterance(word_tokenize(x[1])) for x in imdb_data[2000:2050]]\n",
    "neg_tests = [clean_utterance(word_tokenize(x[1])) for x in imdb_data[-50:]]\n",
    "\n",
    "X1 = []\n",
    "y1 = []\n",
    "\n",
    "for utterance in pos_tests:\n",
    "    for j in range(0, len(utterance) - input_length, step):\n",
    "        buf = encode_sequence(utterance[j:j+input_length])\n",
    "        label = word2id.get(utterance[j+input_length], 0) # assuming <unk> at index 0\n",
    "        if 0 not in buf and word2id['.'] not in buf and label != 0:\n",
    "            X1.append(buf)\n",
    "            y1.append(label)\n",
    "\n",
    "print('number of positive sequences for testing =', len(X1))\n",
    "\n",
    "X2 = []\n",
    "y2 = []\n",
    "\n",
    "for utterance in neg_tests:\n",
    "    for j in range(0, len(utterance) - input_length, step):\n",
    "        buf = encode_sequence(utterance[j:j+input_length])\n",
    "        label = word2id.get(utterance[j+input_length], 0) # assuming <unk> at index 0\n",
    "        if 0 not in buf and word2id['.'] not in buf and label != 0:\n",
    "            X2.append(buf)\n",
    "            y2.append(label)\n",
    "\n",
    "print('number of negative sequences for testing =', len(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84cd162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'small', 'florida', 'beach', 'town']           best = , (0.290)   true = in (0.138)\n",
      "['beach', 'town', 'in', 'the', 'dead']               best = , (0.194)   true = of (0.009)\n",
      "['the', 'dead', 'of', 'winter', 'i']                 best = have (0.187)   true = 've (0.060)\n",
      "['winter', 'i', \"'ve\", 'been', 'there']              best = . (0.162)   true = , (0.153)\n",
      "['been', 'there', ',', 'and', 'this']                best = is (0.424)   true = is (0.424)\n",
      "[\"'s\", 'also', 'the', 'debut', 'feature']            best = of (0.466)   true = of (0.466)\n",
      "['debut', 'feature', 'of', 'actress', 'ashley']      best = judd (0.160)   true = judd (0.160)\n",
      "['actress', 'ashley', 'judd', ',', 'and']            best = a (0.115)   true = she (0.019)\n",
      "[',', 'and', 'she', 'makes', 'a']                    best = lot (0.072)   true = big (0.009)\n",
      "['makes', 'a', 'big', 'impression', 'here']          best = . (0.314)   true = . (0.314)\n",
      "['it', \"'s\", 'hard', 'to', 'believe']                best = that (0.387)   true = this (0.008)\n",
      "['to', 'believe', 'this', 'film', 'is']              best = a (0.108)   true = 12 (0.000)\n",
      "['film', 'is', '12', 'years', 'old']                 best = , (0.212)   true = i (0.034)\n",
      "['years', 'old', 'i', 'remember', 'seeing']          best = this (0.386)   true = it (0.158)\n",
      "['remember', 'seeing', 'it', 'in', 'theaters']       best = , (0.448)   true = , (0.448)\n",
      "['in', 'theaters', ',', 'and', 'i']                  best = was (0.070)   true = recently (0.001)\n",
      "['and', 'i', 'recently', 'rented', 'ruby']           best = again (0.178)   true = again (0.178)\n",
      "['the', '80', \"'s\", 'looking', 'clothes']            best = . (0.274)   true = , (0.216)\n",
      "['looking', 'clothes', ',', 'it', 'has']             best = a (0.239)   true = held (0.001)\n",
      "['it', 'has', 'held', 'up', 'very']                  best = well (0.172)   true = nicely (0.003)\n",
      "['touching', 'here', ',', 'that', 'it']              best = is (0.242)   true = 's (0.195)\n",
      "['that', 'it', \"'s\", 'hard', 'to']                   best = be (0.092)   true = think (0.007)\n",
      "['hard', 'to', 'think', 'of', 'her']                 best = . (0.064)   true = subsequent (0.004)\n",
      "['early', 'promise', '!', 'anyone', 'seeing']        best = this (0.160)   true = ashley (0.001)\n",
      "['anyone', 'seeing', 'ashley', 'here', 'in']         best = the (0.210)   true = ruby (0.001)\n",
      "['here', 'in', 'ruby', 'in', 'paradise']             best = , (0.161)   true = would (0.003)\n",
      "['in', 'paradise', 'would', 'assume', 'this']        best = film (0.224)   true = elegant (0.000)\n",
      "['assume', 'this', 'elegant', ',', 'natural']        best = movie (0.115)   true = beauty (0.020)\n",
      "[',', 'natural', 'beauty', 'went', 'on']             best = the (0.227)   true = to (0.077)\n",
      "['went', 'on', 'to', 'all', 'kinds']                 best = of (0.868)   true = of (0.868)\n",
      "['all', 'kinds', 'of', 'interesting', 'art']         best = . (0.167)   true = films (0.091)\n",
      "['interesting', 'art', 'films', 'and', 'serious']    best = and (0.024)   true = acting (0.003)\n",
      "['and', 'serious', 'acting', 'instead', 'she']       best = is (0.158)   true = has (0.082)\n",
      "['instead', 'she', 'has', 'become', 'the']           best = best (0.089)   true = go (0.000)\n",
      "['become', 'the', 'go', 'to', 'girl']                best = 's (0.070)   true = for (0.008)\n",
      "['to', 'girl', 'for', 'dumb', 'action']              best = films (0.202)   true = films (0.202)\n",
      "['dumb', 'action', 'films', 'and', 'slasher']        best = . (0.061)   true = movies (0.057)\n",
      "['and', 'slasher', 'movies', '!', 'very']            best = well (0.231)   true = disappointing (0.004)\n",
      "['!', 'very', 'disappointing', ',', 'but']           best = it (0.119)   true = at (0.010)\n",
      "[',', 'but', 'at', 'least', 'we']                    best = have (0.110)   true = have (0.110)\n",
      "['least', 'we', 'have', 'this', 'lovely']            best = story (0.103)   true = performance (0.035)\n",
      "[',', 'this', 'is', 'not', 'for']                    best = the (0.158)   true = everyone (0.034)\n",
      "['not', 'for', 'everyone', 'as', 'it']               best = was (0.210)   true = 's (0.126)\n",
      "['as', 'it', \"'s\", 'very', 'slow']                   best = and (0.331)   true = paced (0.052)\n",
      "['not', 'an', 'action', 'film', ',']                 best = but (0.117)   true = nor (0.003)\n",
      "['film', ',', 'nor', 'is', 'it']                     best = 's (0.074)   true = really (0.021)\n",
      "['is', 'it', 'really', 'a', 'romance']               best = , (0.231)   true = . (0.109)\n",
      "['gold', ',', 'another', 'excellent', 'character']   best = , (0.262)   true = study (0.165)\n",
      "['excellent', 'character', 'study', 'treats', 'this']   best = one (0.069)   true = ordinary (0.000)\n",
      "['treats', 'this', 'ordinary', 'young', 'woman']     best = 's (0.273)   true = 's (0.273)\n",
      "['young', 'woman', \"'s\", 'life', 'with']             best = the (0.168)   true = deep (0.000)\n",
      "['life', 'with', 'deep', 'respect', ',']             best = and (0.115)   true = allowing (0.001)\n",
      "['respect', ',', 'allowing', 'her', 'story']         best = to (0.284)   true = to (0.284)\n",
      "['her', 'story', 'to', 'build', 'slowly']            best = and (0.242)   true = and (0.242)\n",
      "['build', 'slowly', 'and', 'with', 'a']              best = very (0.087)   true = lot (0.078)\n",
      "['with', 'a', 'lot', 'of', 'detail']                 best = . (0.196)   true = . (0.196)\n",
      "['in', 'that', 'way', ',', 'i']                      best = was (0.124)   true = think (0.059)\n",
      "[',', 'i', 'think', 'this', 'is']                    best = a (0.294)   true = one (0.077)\n",
      "['this', 'is', 'one', 'of', 'the']                   best = best (0.388)   true = most (0.201)\n",
      "['young', 'women', 'that', 'i', 'can']               best = not (0.068)   true = recall (0.019)\n",
      "['i', 'can', 'recall', 'it', \"'s\"]                   best = not (0.079)   true = not (0.079)\n",
      "['it', \"'s\", 'not', 'about', 'ruby']                 best = 's (0.633)   true = 's (0.633)\n",
      "['but', 'about', 'her', 'life', 'choices']           best = . (0.198)   true = and (0.055)\n",
      "['a', 'lovely', 'film', ',', 'if']                   best = you (0.525)   true = you (0.525)\n",
      "[',', 'if', 'you', 'take', 'the']                    best = movie (0.063)   true = time (0.008)\n",
      "['take', 'the', 'time', 'to', 'watch']               best = . (0.136)   true = it (0.105)\n",
      "['to', 'watch', 'it', '...', 'i']                    best = think (0.105)   true = think (0.105)\n",
      "['...', 'i', 'think', 'it', 'would']                 best = be (0.465)   true = be (0.465)\n",
      "['it', 'would', 'be', 'a', 'really']                 best = good (0.291)   true = excellent (0.004)\n",
      "['a', 'really', 'excellent', 'film', 'to']           best = watch (0.081)   true = show (0.016)\n",
      "['film', 'to', 'show', 'teens', 'and']               best = the (0.057)   true = young (0.001)\n",
      "['teens', 'and', 'young', 'girls', 'or']             best = the (0.070)   true = boys (0.001)\n",
      "['girls', 'or', 'boys', 'for', 'that']               best = . (0.114)   true = matter (0.019)\n",
      "['for', 'that', 'matter', 'and', 'give']             best = it (0.256)   true = them (0.045)\n",
      "['and', 'give', 'them', 'a', 'chance']               best = to (0.573)   true = to (0.573)\n",
      "['a', 'chance', 'to', 'think', 'about']              best = the (0.185)   true = and (0.008)\n",
      "['think', 'about', 'and', 'discuss', 'it.']          best = the (0.173)   true = particular (0.000)\n",
      "['discuss', 'it.', 'particular', 'kudos', 'to']      best = the (0.397)   true = director (0.000)\n",
      "['also', 'wrote', 'the', 'script', ',']              best = but (0.119)   true = which (0.021)\n",
      "['script', ',', 'which', 'is', 'so']                 best = much (0.071)   true = realistic (0.009)\n",
      "['is', 'so', 'realistic', 'and', 'nicely']           best = acted (0.187)   true = detailed (0.001)\n",
      "['and', 'nicely', 'detailed', 'that', 'i']           best = have (0.084)   true = assumed (0.005)\n",
      "['that', 'i', 'assumed', 'all', 'through']           best = the (0.446)   true = the (0.446)\n",
      "['all', 'through', 'the', 'movie', 'that']           best = you (0.102)   true = it (0.069)\n",
      "['movie', 'that', 'it', 'was', 'based']              best = on (0.889)   true = on (0.889)\n",
      "['but', 'in', 'fact', 'it', \"'s\"]                    best = a (0.292)   true = mr. (0.000)\n",
      "['i', 'do', \"n't\", 'know', 'if']                     best = you (0.325)   true = this (0.051)\n",
      "['know', 'if', 'this', 'is', 'a']                    best = movie (0.067)   true = sitcom (0.001)\n",
      "['is', 'a', 'sitcom', 'or', 'not']                   best = to (0.220)   true = , (0.141)\n",
      "['or', 'not', ',', 'but', 'i']                       best = think (0.086)   true = agree (0.001)\n",
      "['but', 'i', 'agree', 'that', 'this']                best = is (0.270)   true = is (0.270)\n",
      "['that', 'this', 'is', 'one', 'of']                  best = the (0.624)   true = the (0.624)\n",
      "['one', 'of', 'the', 'greatest', 'television']       best = series (0.083)   true = shows (0.049)\n",
      "[\"'s\", 'great', 'that', 'this', 'show']              best = is (0.313)   true = still (0.003)\n",
      "['cute', 'on', 'the', 'episodes', 'when']            best = the (0.133)   true = she (0.057)\n",
      "['episodes', 'when', 'she', 'was', 'a']              best = bit (0.054)   true = baby (0.004)\n",
      "['was', 'a', 'baby', 'and', 'she']                   best = 's (0.147)   true = talked (0.001)\n",
      "['and', 'she', 'talked', ',', 'and']                 best = he (0.051)   true = she (0.021)\n",
      "[',', 'and', 'she', 'sometimes', 'said']             best = that (0.177)   true = something (0.002)\n",
      "['this', 'show', 'can', 'relate', 'to']              best = the (0.260)   true = children (0.002)\n",
      "\n",
      "Average probability for next token = 0.109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict(model, h, mode = 'best', true_i = None):\n",
    "    '''\n",
    "    Return a predicted token given the history and the model. Said more simply, predict p[.|h]\n",
    "    with the model and take the best guess or a random guess (depending on mode).\n",
    "    \n",
    "    Note the np.newaxis trick to make believe we have a batch (of size 1) as the model expects\n",
    "    batches.\n",
    "    \n",
    "    Returns predicted token with the corresponding probability, optionnally returning the activation \n",
    "    prob of the true token if true_i is provided\n",
    "    '''\n",
    "    \n",
    "    # pred = model.predict(h[np.newaxis, :], verbose = 0)\n",
    "    pred = model.predict([h], verbose = 0)\n",
    "    \n",
    "    if mode == 'best':\n",
    "        pred_i = np.argmax(pred)\n",
    "    else:\n",
    "        pred_i = random.choice(len(pred), pred)\n",
    "    \n",
    "    return pred_i, pred[0][pred_i], 0 if true_i == None else pred[0][true_i]\n",
    "\n",
    "\n",
    "average_prob = 0\n",
    "i_print = 0\n",
    "\n",
    "for history, label in zip(X1,y1):\n",
    "    best, pred_prob, true_prob = predict(model, history, true_i = label)\n",
    "    average_prob += true_prob\n",
    "\n",
    "    if i_print < 100:\n",
    "        i_print += 1\n",
    "        h_str = str(decode_sequence(history))\n",
    "        print('{:50}   best = {} ({:.3f})   true = {} ({:.3f})'.format(h_str, id2word[best], pred_prob, id2word[label], true_prob))\n",
    "\n",
    "print('\\nAverage probability for next token = {:.3f}'.format(average_prob / len(X1)))\n",
    "\n",
    "#\n",
    "# TODO: check if average probability is in the same order of magnitude for negative examples\n",
    "# or if we have a similar behavior.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc834b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 14, 283, 7, 303]\n",
      "(12, 0.3870387, 0)\n",
      "[14, 283, 7, 303, 12]\n",
      "(1, 0.09925266, 0)\n",
      "[283, 7, 303, 12, 1]\n",
      "(20, 0.058296826, 0)\n",
      "[7, 303, 12, 1, 20]\n",
      "(8, 0.4920028, 0)\n",
      "[303, 12, 1, 20, 8]\n",
      "(5, 0.07880144, 0)\n",
      "[12, 1, 20, 8, 5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'numpy.int64\\'>\"})'}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m prompt \u001b[39m=\u001b[39m encode_sequence([\u001b[39m'\u001b[39m\u001b[39mit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhard\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mto\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbelieve\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# text = encode_sequence(['that', 'the', 'film', 'is', 'not'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# text = encode_sequence(['this', 'is', 'one', 'of', 'the'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# text = encode_sequence(['take', 'the', 'time', 'to', 'watch'])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m sample \u001b[39m=\u001b[39m generate(prompt, model, [word2id[\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(decode_sequence(sample)))\n",
      "\u001b[1;32m/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(MAX_SENTENCE_SIZE):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(text[\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m:])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     output \u001b[39m=\u001b[39m predict(model, text[\u001b[39m-\u001b[39;49m\u001b[39m5\u001b[39;49m:])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     token \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mReturn a predicted token given the history and the model. Said more simply, predict p[.|h]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith the model and take the best guess or a random guess (depending on mode).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprob of the true token if true_i is provided\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# pred = model.predict(h[np.newaxis, :], verbose = 0)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict([h], verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gonem/ENSAI/NLP/nlg-small-to-complete.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     pred_i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(pred)\n",
      "File \u001b[0;32m~/miniforge3/envs/ENSAI/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/ENSAI/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1102\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1104\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'numpy.int64\\'>\"})'}), <class 'NoneType'>"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#\n",
    "# Basic text generation routine starting from a prompt.\n",
    "# \n",
    "\n",
    "MAX_SENTENCE_SIZE = 100\n",
    "\n",
    "#\n",
    "# TODO: This is now your turn to work and write a small loop that generates tokens\n",
    "# following the prompt.  As we discarded all input training sequences with a period,\n",
    "# you should stop generating text whenever we select the period token or when the \n",
    "# limit of MAX_SENTENCE_SIZE is reached.\n",
    "# \n",
    "\n",
    "def generate(prompt, model, stop):\n",
    "    text = prompt\n",
    "\n",
    "    for i in range(MAX_SENTENCE_SIZE):\n",
    "        print(text[-5:])\n",
    "        output = predict(model, text[-5:])\n",
    "        print(output)\n",
    "        token = output[0]\n",
    "        text.append(token)\n",
    "        if token == stop:\n",
    "            break\n",
    "        \n",
    "    return text\n",
    "\n",
    "prompt = encode_sequence(['it', \"'s\", 'hard', 'to', 'believe'])\n",
    "# text = encode_sequence(['that', 'the', 'film', 'is', 'not'])\n",
    "# text = encode_sequence(['this', 'is', 'one', 'of', 'the'])\n",
    "# text = encode_sequence(['take', 'the', 'time', 'to', 'watch'])\n",
    "\n",
    "sample = generate(prompt, model, [word2id['.']])\n",
    "print(' '.join(decode_sequence(sample)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa074c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word2id['.']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENSAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
