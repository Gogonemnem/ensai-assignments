{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = torchvision.datasets.MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
    "mnist_testset = torchvision.datasets.MNIST(root='data', train=False, transform=ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "## Question a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(10, 4))\n",
    "cols, rows = 5, 2\n",
    "for idx in range(1, cols * rows + 1):\n",
    "    img, label = mnist_trainset[idx]\n",
    "    figure.add_subplot(rows, cols, idx)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_limit_dataset(dataset, num_samples=None, labels_list=None):\n",
    "    \"\"\"\n",
    "    Filters and limits the dataset to num_samples and maps the labels to 0 and 1.\n",
    "\n",
    "    dataset: The dataset to filter (e.g., MNIST).\n",
    "    num_samples: The number of samples to include in the filtered dataset.\n",
    "    labels_list: A list or set of two labels to include in the dataset.\n",
    "    \"\"\"\n",
    "    if labels_list is not None:\n",
    "        label_to_binary_map = {label: idx for idx, label in enumerate(labels_list)}\n",
    "        filtered_dataset = [(img, label_to_binary_map[label]) for img, label in dataset if label in labels_list]\n",
    "    else:\n",
    "        # Create a list from the entire dataset if no labels are specified\n",
    "        filtered_dataset = list(dataset)\n",
    "\n",
    "    if num_samples is not None:\n",
    "        return filtered_dataset[:num_samples]\n",
    "    return filtered_dataset\n",
    "\n",
    "# Filter and limit the datasets\n",
    "labels_01 = {0, 1}\n",
    "\n",
    "mnist_trainset_01 = filter_and_limit_dataset(mnist_trainset, 200, labels_01)\n",
    "mnist_testset_01 = filter_and_limit_dataset(mnist_testset, 2000, labels_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_01 = torch.utils.data.DataLoader(mnist_trainset_01, batch_size=64, shuffle=True)\n",
    "val_loader_01 = torch.utils.data.DataLoader(mnist_testset_01, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBinaryMLPSingle(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 10)\n",
    "        self.l2 = torch.nn.Linear(10, 10)\n",
    "        self.l3 = torch.nn.Linear(10, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, image):\n",
    "        flattened_image = image.view(-1, 784)\n",
    "        x = self.sigmoid(self.l1(flattened_image))\n",
    "        x = self.sigmoid(self.l2(x))\n",
    "        x = self.sigmoid(self.l3(x))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBinaryMLPMultiple(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 10)\n",
    "        self.l2 = torch.nn.Linear(10, 10)\n",
    "        self.l3 = torch.nn.Linear(10, 2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, image):\n",
    "        flattened_image = image.view(-1, 784)\n",
    "        x = self.sigmoid(self.l1(flattened_image))\n",
    "        x = self.sigmoid(self.l2(x))\n",
    "        x = self.sigmoid(self.l3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleBinaryMLPSingle(\n",
       "  (l1): Linear(in_features=784, out_features=10, bias=True)\n",
       "  (l2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (l3): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_01 = SimpleBinaryMLPSingle()\n",
    "model_01.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4637, device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_01(mnist_trainset_01[0][0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer_01 = torch.optim.Adam(params =  model_01.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, dataloader, optimizer, loss_function):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (image, target) in enumerate(train_loader_01):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device, dtype=torch.float)\n",
    "\n",
    "        # For MSE Loss with SimpleBinaryMLPMultiple, convert target to one-hot format\n",
    "        if isinstance(model, SimpleBinaryMLPMultiple):\n",
    "            target = target.long()\n",
    "            one_hot_labels = torch.nn.functional.one_hot(target, num_classes=2).float()\n",
    "\n",
    "        outputs = model(image)\n",
    "\n",
    "        # Compute loss\n",
    "        if isinstance(model, SimpleBinaryMLPMultiple):\n",
    "            loss = loss_function(outputs, one_hot_labels)\n",
    "        else:\n",
    "            loss = loss_function(outputs, target.float())  # Assuming target are 0 and 1\n",
    "\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            current = (batch + 1) * len(target)\n",
    "            print(f\"Epoch: {epoch}, loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    print(f\"Epoch: {epoch}, loss: {loss.item():>7f}  [{size:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.256390  [   64/  200]\n",
      "Epoch: 0, loss: 0.261082  [  200/  200]\n",
      "Epoch: 1, loss: 0.253905  [   64/  200]\n",
      "Epoch: 1, loss: 0.251827  [  200/  200]\n",
      "Epoch: 2, loss: 0.262202  [   64/  200]\n",
      "Epoch: 2, loss: 0.270231  [  200/  200]\n",
      "Epoch: 3, loss: 0.249176  [   64/  200]\n",
      "Epoch: 3, loss: 0.261011  [  200/  200]\n",
      "Epoch: 4, loss: 0.256194  [   64/  200]\n",
      "Epoch: 4, loss: 0.260599  [  200/  200]\n",
      "Epoch: 5, loss: 0.253867  [   64/  200]\n",
      "Epoch: 5, loss: 0.241926  [  200/  200]\n",
      "Epoch: 6, loss: 0.249133  [   64/  200]\n",
      "Epoch: 6, loss: 0.251514  [  200/  200]\n",
      "Epoch: 7, loss: 0.254869  [   64/  200]\n",
      "Epoch: 7, loss: 0.279498  [  200/  200]\n",
      "Epoch: 8, loss: 0.250272  [   64/  200]\n",
      "Epoch: 8, loss: 0.232860  [  200/  200]\n",
      "Epoch: 9, loss: 0.252561  [   64/  200]\n",
      "Epoch: 9, loss: 0.241790  [  200/  200]\n",
      "Epoch: 10, loss: 0.254895  [   64/  200]\n",
      "Epoch: 10, loss: 0.241801  [  200/  200]\n",
      "Epoch: 11, loss: 0.257041  [   64/  200]\n",
      "Epoch: 11, loss: 0.241923  [  200/  200]\n",
      "Epoch: 12, loss: 0.254776  [   64/  200]\n",
      "Epoch: 12, loss: 0.251254  [  200/  200]\n",
      "Epoch: 13, loss: 0.254716  [   64/  200]\n",
      "Epoch: 13, loss: 0.260504  [  200/  200]\n",
      "Epoch: 14, loss: 0.250012  [   64/  200]\n",
      "Epoch: 14, loss: 0.269792  [  200/  200]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train(model_01, epoch, train_loader_01, optimizer_01, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradient needed\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            if isinstance(model, SimpleBinaryMLPSingle):\n",
    "                # For SimpleBinaryMLPSingle, use 0.5 threshold for binary classification\n",
    "                predicted = outputs >= 0.5\n",
    "            else: # isinstance(model, SimpleBinaryMLPMultiple):\n",
    "                # For SimpleBinaryMLPMultiple, select the class with the higher score\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 46.40%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test data\n",
    "test_accuracy = validate(val_loader_01, model_01)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and limit the datasets\n",
    "labels_49 = [4, 9]\n",
    "\n",
    "mnist_trainset_49 = filter_and_limit_dataset(mnist_trainset, 200, labels_49)\n",
    "mnist_testset_49 = filter_and_limit_dataset(mnist_testset, 2000, labels_49)\n",
    "\n",
    "train_loader_49 = torch.utils.data.DataLoader(mnist_trainset_01, batch_size=64, shuffle=True)\n",
    "val_loader_49 = torch.utils.data.DataLoader(mnist_testset_01, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleBinaryMLPMultiple(\n",
       "  (l1): Linear(in_features=784, out_features=10, bias=True)\n",
       "  (l2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (l3): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_49 = SimpleBinaryMLPMultiple()\n",
    "model_49.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer_49 = torch.optim.Adam(params =  model_49.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.277226  [   64/  200]\n",
      "Epoch: 0, loss: 0.291793  [  200/  200]\n",
      "Epoch: 1, loss: 0.277033  [   64/  200]\n",
      "Epoch: 1, loss: 0.264441  [  200/  200]\n",
      "Epoch: 2, loss: 0.281700  [   64/  200]\n",
      "Epoch: 2, loss: 0.245944  [  200/  200]\n",
      "Epoch: 3, loss: 0.279343  [   64/  200]\n",
      "Epoch: 3, loss: 0.273670  [  200/  200]\n",
      "Epoch: 4, loss: 0.272508  [   64/  200]\n",
      "Epoch: 4, loss: 0.291773  [  200/  200]\n",
      "Epoch: 5, loss: 0.280411  [   64/  200]\n",
      "Epoch: 5, loss: 0.264232  [  200/  200]\n",
      "Epoch: 6, loss: 0.276971  [   64/  200]\n",
      "Epoch: 6, loss: 0.273436  [  200/  200]\n",
      "Epoch: 7, loss: 0.280263  [   64/  200]\n",
      "Epoch: 7, loss: 0.282406  [  200/  200]\n",
      "Epoch: 8, loss: 0.277891  [   64/  200]\n",
      "Epoch: 8, loss: 0.264078  [  200/  200]\n",
      "Epoch: 9, loss: 0.275667  [   64/  200]\n",
      "Epoch: 9, loss: 0.300625  [  200/  200]\n",
      "Epoch: 10, loss: 0.274410  [   64/  200]\n",
      "Epoch: 10, loss: 0.282551  [  200/  200]\n",
      "Epoch: 11, loss: 0.270866  [   64/  200]\n",
      "Epoch: 11, loss: 0.282384  [  200/  200]\n",
      "Epoch: 12, loss: 0.273266  [   64/  200]\n",
      "Epoch: 12, loss: 0.291747  [  200/  200]\n",
      "Epoch: 13, loss: 0.276607  [   64/  200]\n",
      "Epoch: 13, loss: 0.254728  [  200/  200]\n",
      "Epoch: 14, loss: 0.276627  [   64/  200]\n",
      "Epoch: 14, loss: 0.282239  [  200/  200]\n",
      "Epoch: 15, loss: 0.277573  [   64/  200]\n",
      "Epoch: 15, loss: 0.291666  [  200/  200]\n",
      "Epoch: 16, loss: 0.278629  [   64/  200]\n",
      "Epoch: 16, loss: 0.264191  [  200/  200]\n",
      "Epoch: 17, loss: 0.276349  [   64/  200]\n",
      "Epoch: 17, loss: 0.272961  [  200/  200]\n",
      "Epoch: 18, loss: 0.272890  [   64/  200]\n",
      "Epoch: 18, loss: 0.282165  [  200/  200]\n",
      "Epoch: 19, loss: 0.272806  [   64/  200]\n",
      "Epoch: 19, loss: 0.282064  [  200/  200]\n",
      "Epoch: 20, loss: 0.276292  [   64/  200]\n",
      "Epoch: 20, loss: 0.300322  [  200/  200]\n",
      "Epoch: 21, loss: 0.276220  [   64/  200]\n",
      "Epoch: 21, loss: 0.282040  [  200/  200]\n",
      "Epoch: 22, loss: 0.281956  [   64/  200]\n",
      "Epoch: 22, loss: 0.263844  [  200/  200]\n",
      "Epoch: 23, loss: 0.270429  [   64/  200]\n",
      "Epoch: 23, loss: 0.282021  [  200/  200]\n",
      "Epoch: 24, loss: 0.280664  [   64/  200]\n",
      "Epoch: 24, loss: 0.281927  [  200/  200]\n",
      "Epoch: 25, loss: 0.278267  [   64/  200]\n",
      "Epoch: 25, loss: 0.281616  [  200/  200]\n",
      "Epoch: 26, loss: 0.275872  [   64/  200]\n",
      "Epoch: 26, loss: 0.253953  [  200/  200]\n",
      "Epoch: 27, loss: 0.272297  [   64/  200]\n",
      "Epoch: 27, loss: 0.272580  [  200/  200]\n",
      "Epoch: 28, loss: 0.274668  [   64/  200]\n",
      "Epoch: 28, loss: 0.299756  [  200/  200]\n",
      "Epoch: 29, loss: 0.277993  [   64/  200]\n",
      "Epoch: 29, loss: 0.235651  [  200/  200]\n",
      "Epoch: 30, loss: 0.278110  [   64/  200]\n",
      "Epoch: 30, loss: 0.262951  [  200/  200]\n",
      "Epoch: 31, loss: 0.269952  [   64/  200]\n",
      "Epoch: 31, loss: 0.281738  [  200/  200]\n",
      "Epoch: 32, loss: 0.276883  [   64/  200]\n",
      "Epoch: 32, loss: 0.262608  [  200/  200]\n",
      "Epoch: 33, loss: 0.268649  [   64/  200]\n",
      "Epoch: 33, loss: 0.272525  [  200/  200]\n",
      "Epoch: 34, loss: 0.273319  [   64/  200]\n",
      "Epoch: 34, loss: 0.253597  [  200/  200]\n",
      "Epoch: 35, loss: 0.281302  [   64/  200]\n",
      "Epoch: 35, loss: 0.290203  [  200/  200]\n",
      "Epoch: 36, loss: 0.273178  [   64/  200]\n",
      "Epoch: 36, loss: 0.290309  [  200/  200]\n",
      "Epoch: 37, loss: 0.274323  [   64/  200]\n",
      "Epoch: 37, loss: 0.253682  [  200/  200]\n",
      "Epoch: 38, loss: 0.277726  [   64/  200]\n",
      "Epoch: 38, loss: 0.262852  [  200/  200]\n",
      "Epoch: 39, loss: 0.271930  [   64/  200]\n",
      "Epoch: 39, loss: 0.281182  [  200/  200]\n",
      "Epoch: 40, loss: 0.276500  [   64/  200]\n",
      "Epoch: 40, loss: 0.290292  [  200/  200]\n",
      "Epoch: 41, loss: 0.274049  [   64/  200]\n",
      "Epoch: 41, loss: 0.281166  [  200/  200]\n",
      "Epoch: 42, loss: 0.282128  [   64/  200]\n",
      "Epoch: 42, loss: 0.243584  [  200/  200]\n",
      "Epoch: 43, loss: 0.278813  [   64/  200]\n",
      "Epoch: 43, loss: 0.299348  [  200/  200]\n",
      "Epoch: 44, loss: 0.276264  [   64/  200]\n",
      "Epoch: 44, loss: 0.262323  [  200/  200]\n",
      "Epoch: 45, loss: 0.275033  [   64/  200]\n",
      "Epoch: 45, loss: 0.271684  [  200/  200]\n",
      "Epoch: 46, loss: 0.272729  [   64/  200]\n",
      "Epoch: 46, loss: 0.281037  [  200/  200]\n",
      "Epoch: 47, loss: 0.278519  [   64/  200]\n",
      "Epoch: 47, loss: 0.261955  [  200/  200]\n",
      "Epoch: 48, loss: 0.273725  [   64/  200]\n",
      "Epoch: 48, loss: 0.262292  [  200/  200]\n",
      "Epoch: 49, loss: 0.274939  [   64/  200]\n",
      "Epoch: 49, loss: 0.271001  [  200/  200]\n",
      "Epoch: 50, loss: 0.273745  [   64/  200]\n",
      "Epoch: 50, loss: 0.280566  [  200/  200]\n",
      "Epoch: 51, loss: 0.270215  [   64/  200]\n",
      "Epoch: 51, loss: 0.289602  [  200/  200]\n",
      "Epoch: 52, loss: 0.273553  [   64/  200]\n",
      "Epoch: 52, loss: 0.271019  [  200/  200]\n",
      "Epoch: 53, loss: 0.270048  [   64/  200]\n",
      "Epoch: 53, loss: 0.280529  [  200/  200]\n",
      "Epoch: 54, loss: 0.278078  [   64/  200]\n",
      "Epoch: 54, loss: 0.271435  [  200/  200]\n",
      "Epoch: 55, loss: 0.272291  [   64/  200]\n",
      "Epoch: 55, loss: 0.289621  [  200/  200]\n",
      "Epoch: 56, loss: 0.277967  [   64/  200]\n",
      "Epoch: 56, loss: 0.289783  [  200/  200]\n",
      "Epoch: 57, loss: 0.273305  [   64/  200]\n",
      "Epoch: 57, loss: 0.289633  [  200/  200]\n",
      "Epoch: 58, loss: 0.273267  [   64/  200]\n",
      "Epoch: 58, loss: 0.298966  [  200/  200]\n",
      "Epoch: 59, loss: 0.269878  [   64/  200]\n",
      "Epoch: 59, loss: 0.252308  [  200/  200]\n",
      "Epoch: 60, loss: 0.273220  [   64/  200]\n",
      "Epoch: 60, loss: 0.252476  [  200/  200]\n",
      "Epoch: 61, loss: 0.274366  [   64/  200]\n",
      "Epoch: 61, loss: 0.280002  [  200/  200]\n",
      "Epoch: 62, loss: 0.276564  [   64/  200]\n",
      "Epoch: 62, loss: 0.289100  [  200/  200]\n",
      "Epoch: 63, loss: 0.279014  [   64/  200]\n",
      "Epoch: 63, loss: 0.280071  [  200/  200]\n",
      "Epoch: 64, loss: 0.272958  [   64/  200]\n",
      "Epoch: 64, loss: 0.289344  [  200/  200]\n",
      "Epoch: 65, loss: 0.274190  [   64/  200]\n",
      "Epoch: 65, loss: 0.279778  [  200/  200]\n",
      "Epoch: 66, loss: 0.276498  [   64/  200]\n",
      "Epoch: 66, loss: 0.260844  [  200/  200]\n",
      "Epoch: 67, loss: 0.278658  [   64/  200]\n",
      "Epoch: 67, loss: 0.252080  [  200/  200]\n",
      "Epoch: 68, loss: 0.273928  [   64/  200]\n",
      "Epoch: 68, loss: 0.279869  [  200/  200]\n",
      "Epoch: 69, loss: 0.278521  [   64/  200]\n",
      "Epoch: 69, loss: 0.270531  [  200/  200]\n",
      "Epoch: 70, loss: 0.272896  [   64/  200]\n",
      "Epoch: 70, loss: 0.270365  [  200/  200]\n",
      "Epoch: 71, loss: 0.278352  [   64/  200]\n",
      "Epoch: 71, loss: 0.261094  [  200/  200]\n",
      "Epoch: 72, loss: 0.270407  [   64/  200]\n",
      "Epoch: 72, loss: 0.279935  [  200/  200]\n",
      "Epoch: 73, loss: 0.275999  [   64/  200]\n",
      "Epoch: 73, loss: 0.279904  [  200/  200]\n",
      "Epoch: 74, loss: 0.278187  [   64/  200]\n",
      "Epoch: 74, loss: 0.251446  [  200/  200]\n",
      "Epoch: 75, loss: 0.280704  [   64/  200]\n",
      "Epoch: 75, loss: 0.260499  [  200/  200]\n",
      "Epoch: 76, loss: 0.274913  [   64/  200]\n",
      "Epoch: 76, loss: 0.269972  [  200/  200]\n",
      "Epoch: 77, loss: 0.271189  [   64/  200]\n",
      "Epoch: 77, loss: 0.298128  [  200/  200]\n",
      "Epoch: 78, loss: 0.267725  [   64/  200]\n",
      "Epoch: 78, loss: 0.279009  [  200/  200]\n",
      "Epoch: 79, loss: 0.270925  [   64/  200]\n",
      "Epoch: 79, loss: 0.270463  [  200/  200]\n",
      "Epoch: 80, loss: 0.273306  [   64/  200]\n",
      "Epoch: 80, loss: 0.279212  [  200/  200]\n",
      "Epoch: 81, loss: 0.265195  [   64/  200]\n",
      "Epoch: 81, loss: 0.260777  [  200/  200]\n",
      "Epoch: 82, loss: 0.270937  [   64/  200]\n",
      "Epoch: 82, loss: 0.270031  [  200/  200]\n",
      "Epoch: 83, loss: 0.275639  [   64/  200]\n",
      "Epoch: 83, loss: 0.251326  [  200/  200]\n",
      "Epoch: 84, loss: 0.272131  [   64/  200]\n",
      "Epoch: 84, loss: 0.278363  [  200/  200]\n",
      "Epoch: 85, loss: 0.282607  [   64/  200]\n",
      "Epoch: 85, loss: 0.269674  [  200/  200]\n",
      "Epoch: 86, loss: 0.274386  [   64/  200]\n",
      "Epoch: 86, loss: 0.241153  [  200/  200]\n",
      "Epoch: 87, loss: 0.270847  [   64/  200]\n",
      "Epoch: 87, loss: 0.297080  [  200/  200]\n",
      "Epoch: 88, loss: 0.274300  [   64/  200]\n",
      "Epoch: 88, loss: 0.269704  [  200/  200]\n",
      "Epoch: 89, loss: 0.275358  [   64/  200]\n",
      "Epoch: 89, loss: 0.279314  [  200/  200]\n",
      "Epoch: 90, loss: 0.270619  [   64/  200]\n",
      "Epoch: 90, loss: 0.269982  [  200/  200]\n",
      "Epoch: 91, loss: 0.278874  [   64/  200]\n",
      "Epoch: 91, loss: 0.279080  [  200/  200]\n",
      "Epoch: 92, loss: 0.277478  [   64/  200]\n",
      "Epoch: 92, loss: 0.251066  [  200/  200]\n",
      "Epoch: 93, loss: 0.277452  [   64/  200]\n",
      "Epoch: 93, loss: 0.250802  [  200/  200]\n",
      "Epoch: 94, loss: 0.271501  [   64/  200]\n",
      "Epoch: 94, loss: 0.288163  [  200/  200]\n",
      "Epoch: 95, loss: 0.269267  [   64/  200]\n",
      "Epoch: 95, loss: 0.268815  [  200/  200]\n",
      "Epoch: 96, loss: 0.267977  [   64/  200]\n",
      "Epoch: 96, loss: 0.269082  [  200/  200]\n",
      "Epoch: 97, loss: 0.276084  [   64/  200]\n",
      "Epoch: 97, loss: 0.250232  [  200/  200]\n",
      "Epoch: 98, loss: 0.271474  [   64/  200]\n",
      "Epoch: 98, loss: 0.259556  [  200/  200]\n",
      "Epoch: 99, loss: 0.268957  [   64/  200]\n",
      "Epoch: 99, loss: 0.268822  [  200/  200]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train(model_49, epoch, train_loader_49, optimizer_49, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 46.40%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test data\n",
    "test_accuracy = validate(val_loader_49, model_49)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def prepare_data_for_lda(dataset):\n",
    "    images = [img.numpy().reshape(-1) for img, _ in dataset]\n",
    "    labels = [label for _, label in dataset]\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Prepare data\n",
    "X_train_01, y_train_01 = prepare_data_for_lda(mnist_trainset_01)\n",
    "X_test_01, y_test_01 = prepare_data_for_lda(mnist_testset_01)\n",
    "\n",
    "X_train_49, y_train_49 = prepare_data_for_lda(mnist_trainset_49)\n",
    "X_test_49, y_test_49 = prepare_data_for_lda(mnist_testset_49)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train LDA model for 0 and 1\n",
    "lda_01 = LinearDiscriminantAnalysis()\n",
    "lda_01.fit(X_train_01, y_train_01)\n",
    "\n",
    "# Train LDA model for 4 and 9\n",
    "lda_49 = LinearDiscriminantAnalysis()\n",
    "lda_49.fit(X_train_49, y_train_49)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy for 0 and 1: 99.35%\n",
      "LDA Accuracy for 4 and 9: 89.65%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LDA model on test data\n",
    "y_pred_01 = lda_01.predict(X_test_01)\n",
    "accuracy_01 = 100 * accuracy_score(y_test_01, y_pred_01)\n",
    "print(f\"LDA Accuracy for 0 and 1: {accuracy_01:.2f}%\")\n",
    "\n",
    "y_pred_49 = lda_49.predict(X_test_49)\n",
    "accuracy_49 = 100 * accuracy_score(y_test_49, y_pred_49)\n",
    "print(f\"LDA Accuracy for 4 and 9: {accuracy_49:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = torch.nn.Sequential(            \n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=4, out_channels=12, kernel_size=5, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=12, out_channels=n_classes, kernel_size=4, stride=1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        logits = torch.flatten(x, 1)\n",
    "        # logits = self.classifier(x)\n",
    "        # probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        return logits#, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(4, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Conv2d(12, 10, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv = ConvNet(10)\n",
    "model_conv.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_conv.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset_1000 = filter_and_limit_dataset(mnist_trainset, 1000)\n",
    "\n",
    "train_loader_1000 = torch.utils.data.DataLoader(mnist_trainset_1000, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv(model, epoch, dataloader, optimizer, loss_function):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (image, target) in enumerate(dataloader):\n",
    "        image = image.to(device)\n",
    "        # Target for CrossEntropyLoss should be of long type and not one-hot encoded\n",
    "        target = target.to(device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(image)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, target)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            current = (batch + 1) * len(target)\n",
    "            print(f\"Epoch: {epoch}, batch_loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    print(f\"Epoch: {epoch}, batch_loss: {loss.item():>7f}  [{size:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch_loss: 1.241809  [   64/ 1000]\n",
      "Epoch: 0, batch_loss: 0.985205  [ 1000/ 1000]\n",
      "Epoch: 1, batch_loss: 1.153422  [   64/ 1000]\n",
      "Epoch: 1, batch_loss: 1.214937  [ 1000/ 1000]\n",
      "Epoch: 2, batch_loss: 1.373251  [   64/ 1000]\n",
      "Epoch: 2, batch_loss: 1.053423  [ 1000/ 1000]\n",
      "Epoch: 3, batch_loss: 1.157856  [   64/ 1000]\n",
      "Epoch: 3, batch_loss: 0.813568  [ 1000/ 1000]\n",
      "Epoch: 4, batch_loss: 1.272192  [   64/ 1000]\n",
      "Epoch: 4, batch_loss: 1.118268  [ 1000/ 1000]\n",
      "Epoch: 5, batch_loss: 1.282182  [   64/ 1000]\n",
      "Epoch: 5, batch_loss: 1.099139  [ 1000/ 1000]\n",
      "Epoch: 6, batch_loss: 1.018999  [   64/ 1000]\n",
      "Epoch: 6, batch_loss: 1.160407  [ 1000/ 1000]\n",
      "Epoch: 7, batch_loss: 1.429004  [   64/ 1000]\n",
      "Epoch: 7, batch_loss: 1.154202  [ 1000/ 1000]\n",
      "Epoch: 8, batch_loss: 0.991560  [   64/ 1000]\n",
      "Epoch: 8, batch_loss: 1.267465  [ 1000/ 1000]\n",
      "Epoch: 9, batch_loss: 1.199132  [   64/ 1000]\n",
      "Epoch: 9, batch_loss: 1.157305  [ 1000/ 1000]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    train_conv(model_conv, epoch, train_loader_1000, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy ConvNet: 53.78%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_conv = validate(val_loader, model_conv)\n",
    "print(f'Test Accuracy ConvNet: {test_accuracy_conv:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENSAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
